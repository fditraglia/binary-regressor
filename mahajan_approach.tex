%!TEX root = ./main.tex
\section{Comment on \cite{Mahajan} A.2}
\label{sec:mahajan}
Expanding on our discussion from Section \ref{sec:ident_literature} above, we now show that \citeauthor{Mahajan}'s identification argument for an endogenous regressor in an additively separable model (A.2) is incorrect.
Unless otherwise indicated, all notation used below is as defined in Section \ref{sec:identification}.

The first step of \cite{Mahajan} A.2 argues (correctly) that under Assumptions \ref{assump:model} and \ref{assump:misclassification} (i)--(ii), knowledge of $\alpha_0(\mathbf{x})$ and $\alpha_1(\mathbf{x})$ is sufficient to identify $\beta(\mathbf{x})$. 
This step is equivalent to our Lemma \ref{lem:wald} above.
The second step appeals to \cite{Mahajan} Theorem 1 to argue that $\alpha_0(\mathbf{x})$ and $\alpha_1(\mathbf{x})$ are indeed point identified.
To understand the logic of this second step, we first re-state \cite{Mahajan} Theorem 1 in our notation.
As in Section \ref{sec:identification} above, $T^*$ denotes an unobserved binary random variable, $z$ is a instrument, $T$ an observed binary surrogate for $T^*$, $y$ an outcome of interest, and $\mathbf{x}$ a vector covariates.

\begin{assump}[\cite{Mahajan} Theorem 1]
  Define $g(T^*, \mathbf{x}) \equiv \mathbb{E}[y|\mathbf{x},T^*]$ and $v \equiv y - g(T^*,\mathbf{x})$.
  Suppose that knowledge of $(y,T^*,\mathbf{x})$ is sufficient to identify $g$ and that:
  \begin{enumerate}[(i)]
    \item $\mathbb{P}(T^*=1|\mathbf{x},z=0) \neq \mathbb{P}(T^*=1|\mathbf{x},z=1)$.
    \item $T$ is conditionally independent of $z$ given $(\mathbf{x}, T^*)$.
    \item $\alpha_0(\mathbf{x}) + \alpha_1(\mathbf{x}) < 1$
    \item $\mathbb{E}[v|\mathbf{x},z,T^*,T] = 0$
    \item $g(1,\mathbf{x}) \neq g(0, \mathbf{x})$
  \end{enumerate}
  \label{assump:mahajan1}
\end{assump}

\begin{thm}[\cite{Mahajan} Theorem 1]
  Under Assumption \ref{assump:mahajan1}, $\alpha_0(\mathbf{x})$ and $\alpha_1(\mathbf{x})$ are point identified, as is $g(T^*,\mathbf{x})$.
  \label{thm:mahajan1}
\end{thm}

Assumption \ref{assump:mahajan1} (i) is equivalent to our Assumption \ref{assump:model} (ii), while Assumptions \ref{assump:mahajan1} (ii)--(iii) are equivalent to our Assumptions \ref{assump:misclassification} (i)--(ii).
Assumption \ref{assump:mahajan1} (v) serves the same purpose as $\beta(\mathbf{x}) \neq 0$ in our Theorem \ref{thm:main_ident}: unless $T^*$ affects $y$, we cannot identify the mis-classification probabilities.
The key difference between Theorem \ref{thm:mahajan1} and the setting we consider in Section \ref{sec:identification} comes from Assumption \ref{assump:mahajan1} (iv). 
This is essentially a stronger version of our Assumptions \ref{assump:model} (iii) and \ref{assump:misclassification} (iii) but applies to the \emph{projection error} $v$, defined in Assumption \ref{assump:mahajan1} rather than the structural error $\varepsilon$, defined in Assumption \ref{assump:model} (i).
Accordingly, Theorem \ref{thm:mahajan1} identifies the conditional mean function $g$ rather than the causal effect $\beta(\mathbf{x})$.

Although the meaning of the error term changes when we move from a structural to a reduced form model, the meaning of the mis-classification error rates does not: $\alpha_0(\mathbf{x})$ and $\alpha_1(\mathbf{x})$ are simply conditional probabilities for $T$ given $(T^*,\mathbf{x})$.
Step 2 of \cite{Mahajan} A.2 relies on this insight.
%The idea is to find an additional condition under which Assumptions \ref{assump:model} (iii) and \ref{assump:misclassification} (iii) imply Assumption \ref{assump:mahajan1} (iv) while allowing $T^*$ to be endogenous.
The idea is to find a way to satisfy Assumption \ref{assump:mahajan1} (iv) simultaneously with Assumptions \ref{assump:model} (iii) and \ref{assump:misclassification} (iii), while allowing $T^*$ to be endogenous.
If this can be achieved, $\alpha_0(\mathbf{x}), \alpha_1(\mathbf{x})$ will be identified via Theorem \ref{thm:mahajan1}, and identification of $\beta(\mathbf{x})$ will follow from step 1 of A.2 (our Lemma \ref{lem:wald}).
To this end, \cite{Mahajan} invokes the condition 
\begin{equation}
  \mathbb{E}(y|\mathbf{x},z,T^*,T) = \mathbb{E}(y|\mathbf{x},T^*).
  \label{eq:mahajan11}
\end{equation}
Because \cite{Mahajan} A.2 assumes an additively separable model -- our Assumption \ref{assump:model} (i) -- we see that
\[
  \mathbb{E}(y|\mathbf{x},z,T^*,T) = c(\mathbf{x}) + \beta(\mathbf{x}) T^* + \mathbb{E}(\varepsilon|\mathbf{x},z,T^*,T)
\]
so Equation \ref{eq:mahajan11} is equivalent to $\mathbb{E}(\varepsilon|\mathbf{x},z,T^*,T)=\mathbb{E}(\varepsilon|\mathbf{x},T^*)$.
Note that this allows $T^*$ to be endogenous, as it does not require $\mathbb{E}(\varepsilon|\mathbf{x},T^*)=0$.
Now, applying Equation \ref{eq:mahajan11} to the definition of $v$ from Assumption \ref{assump:mahajan1}, we have
\[
  \mathbb{E}(v|\mathbf{x},z,T^*,T) = \mathbb{E}\left[ y - \mathbb{E}(y|\mathbf{x},T^*)\left. \right|\mathbf{x},z,T^*,T \right] = 0
\]
which satisfies Assumption \ref{assump:mahajan1} (iv) as required.
Based on this reasoning, \cite{Mahajan} claims that Equation \ref{eq:mahajan11} along with Assumptions \ref{assump:model}, \ref{assump:misclassification} (i)--(ii), and \ref{assump:mahajan1} suffice to identify the effect $\beta(\mathbf{x})$ of an endogenous $T^*$, so long as $g(1,\mathbf{x}) \neq g(0,\mathbf{x})$.
As we now show, however, these Assumptions are contradictory unless $T^*$ is exogenous.

By Equation \ref{eq:mahajan11} and Assumption \ref{assump:model} (i), $\mathbb{E}(\varepsilon|\mathbf{x},z,T^*,T)=\mathbb{E}(\varepsilon|\mathbf{x},T^*)$ and thus by iterated expectations, we obtain
\begin{equation}
  \mathbb{E}(\varepsilon|\mathbf{x},T^*,z) = \mathbb{E}_{T|\mathbf{x},T^*,z}\left[ \mathbb{E}(\varepsilon|\mathbf{x},T^*,T,z) \right] = \mathbb{E}_{T|\mathbf{x},T^*,z}\left[ \mathbb{E}(\varepsilon|\mathbf{x},T^*) \right] = \mathbb{E}(\varepsilon|\mathbf{x}, T^*).
  \label{eq:zdiffs}
\end{equation}
Now, let $m^*_{tk}(\mathbf{x}) = \mathbb{E}(\varepsilon|\mathbf{x}, T^*=t,z=k)$.
Using this notation, Equation \ref{eq:zdiffs} is equivalent to $m^*_{t0}(\mathbf{x}) = m^*_{t1}(\mathbf{x})$ for $t = 0, 1$.
Combining iterated expectations with Assumption \ref{assump:model} (iii), 
\begin{equation}
  \mathbb{E}(\varepsilon|\mathbf{x},z=k) = [1 - p^*_k(\mathbf{x})] m^*_{0k}(\mathbf{x}) + p^*_k(\mathbf{x}) m^*_{1k}(\mathbf{x}) = 0 
  \label{eq:eps}
\end{equation}
for $k = 0,1$ where $p^*_k(\mathbf{x}) \equiv \mathbb{P}(T^*=1|\mathbf{x}, z=k)$.
But substituting $m^*_{t0}(\mathbf{x}) = m^*_{t1}(\mathbf{x})$ into Equation \ref{eq:eps} for $k=0,1$, we obtain 
\begin{align*}
  [1 - p^*_0(\mathbf{x})] m^*_{00}(\mathbf{x}) + p^*_0(\mathbf{x}) m^*_{10}(\mathbf{x}) &= 0\\ 
  [1 - p^*_1(\mathbf{x})] m^*_{00}(\mathbf{x}) + p^*_1(\mathbf{x}) m^*_{10}(\mathbf{x}) &= 0
\end{align*}
Both of the preceding two equalities are convex combinations of $m^*_{00}$ and $m^*_{10}$.
The only way that both can equal zero simultaneously is if either $p^*_0(\mathbf{x}) = p^*_1(\mathbf{x})$, contradicting Assumption \ref{assump:model} (ii), or if $m^*_{tk}(\mathbf{x}) = 0$ for all $(t,k)$, which implies that $T^*$ is exogenous.
Hence \cite{Mahajan} A.2 fails: given the assumption that $z$ is a valid instrument for $\varepsilon$, Equation \ref{eq:mahajan11} implies that either there is no first-stage relationship between $z$ and $T^*$ or that $T^*$ is exogenous.

The root of the problem with A.2 is the attempt to use \emph{one} instrument to satisfy both the assumptions of Theorem \ref{thm:mahajan1} and Lemma \ref{lem:wald}.
If one had access to a second instrument $w$, or equivalently a second mis-measured surrogate for $T^*$, that satisfied Assumptions \ref{assump:mahajan1}, one could use $w$  to recover $\alpha_0(\mathbf{x})$ and $\alpha_1(\mathbf{x})$ via Theorem \ref{thm:mahajan1} and $z$ to recover the IV estimand $\beta(\mathbf{x}) / [1 - \alpha_0(\mathbf{x}) - \alpha_1(\mathbf{x})]$ via Lemma \ref{lem:wald}.
This is effectively the approach used by \cite{Batt} to evaluate the returns to schooling in a setting with multiple misreported measures of educational qualifications.

%To understand the economic intuition behind Proposition ???, consider a simple example in which we randomize the offer of a job training program to a sample of workers to study the impact on future earnings.
%In this context $z$ indicates whether a particular individual is \emph{offered} job training by the experimenter while $T^*$ indicates whether she actually \emph{obtains} job training from any source, inside or outside of the experiment.
%We observe not $T^*$ but a self-report $T$ that is measured with error.
%In this example $u$ contains all of the unobservable factors that determine an individual's wage.
%
%Assumption ??? allows for endogenous treatment receipt: $\mathbb{E}[u|T^*=1]$ may be different from $\mathbb{E}[u|T^*=0]$.
%We might expect, for example, that individuals who obtain job training are more motivated than those who do not, and hence earn higher wages on average. 
%However, Assumption ??? imposes that $\mathbb{E}\left[u|T^*=t,z_1 \right]=\mathbb{E}\left[ u|T^*=t,z_2 \right]$ for $t=0,1$.
%This has two implications.
%First, it means that, among those who do not obtain job training, the average value of $u$ is the same for those who were offered training and those who were not.
%Second, it means that, among those who \emph{did} obtain job training, the average value of $u$ is the same for those who were offered training and those who were not.
%In other words, Assumption ??? requires that there is \emph{no selection on unobservables}.
%This is exactly the opposite of what we would expect in the job training setting.
%For example, individuals who are offered job training but refuse it, are likely to be very different from those who are not offered training and fail to obtain it from an outside source. 
%And herein lies the problem: Assumption ??? simultaneously allows endogeneity and rules out selection.
%Given that the offer of job training is randomly assigned, and hence a valid instrument, the only way to avoid a contradiction is if there is no first stage: the fraction of individuals who take up job training cannot depend on the offer of training.
% 
