%!TEX root = ./main.tex
\section{Simulation Study}

In this section we present results from a simulation study using the inference procedure described in Section \ref{sec:details} above.
Unless otherwise specified, all calculations are based on $2000$ simulation replications with $n = 1000$ using Algorithm \ref{alg:Bonferroni} with $R = 5000$ simulation draws.
Supplementary simulation results appear in Appendix \ref{sec:simulation_supplement}.

\subsection{Simulation DGP}
\label{sec:DGP}
Our simulation design generates $n$ iid observations of the observables $(y_i, T_i, z)$ as follows:
\begin{enumerate}
  \item Generate the instrumental variable $z$.
    \begin{enumerate}[(i)]
      \item For each $1 \leq i \leq n/2$ set $z_i = 0$.
      \item For each $n/2 < i \leq n$, set $z_i = 1$.
    \end{enumerate}
  \item Generate the error terms: 
    \[
      \left[
      \begin{array}{c}
        \eta_i \\ \varepsilon_i
      \end{array}
    \right] \sim \mbox{iid N}\left( \left[
\begin{array}{c}
  0 \\ 0
\end{array}
\right], \left[
\begin{array}{cc}
  1 & \rho \\
  \rho & 1
\end{array}
\right]\right).
\]
  \item Generate the unobserved regressor: $T^*_i = \mathbf{1}\left\{ d_0 + d_1 z_i + \eta_i > 0 \right\}$.
  \item Generate the outcome: $y_i = c + \beta T_i^* + \varepsilon_i$.  
  \item Generate the observed, mis-classified regressor $T$.
    \begin{enumerate}[(i)]
      \item For all $i$ with $T^*_i = 0$ draw $T_i \sim \mbox{iid Bernoulli}(\alpha_0)$. 
      \item For all $i$ with $T^*_i = 1$ draw $T_i \sim \mbox{iid Bernoulli}(1 - \alpha_1)$.
    \end{enumerate}
\end{enumerate}
This DGP generates random variables that satisfy the conditions of Theorems \ref{thm:sharpII} and \ref{thm:main_ident}.
Thus $\beta$ is point identified, and all moment equalities and inequalities from Section \ref{sec:inference} hold at the true parameter values of the DGP.
Note from step 1 that we hold \emph{condition} on the instrument $z$, holding it fixed in repeated samples.
Our simulation varies the parameters $(\alpha_0, \alpha_1, \beta, n)$ over a grid.
Because $\varepsilon$ has unit variance, values for $\beta$ are measured in standard deviations of the error.
For simplicity we present results for $c = 0, d_0 = \Phi^{-1}(0.15)$, and  $d_1= \Phi^{-1}(0.85) - \Phi^{-1}(0.15)$, where $\Phi^{-1}(\cdot)$ denotes the quantile function of a standard normal random variable.
Using these values for $(d_0, d_1)$ holds the unobserved first stage probabilities fixed: $p^*_0 = 0.15$ and $p^*_1 = 0.85$.
In contrast the \emph{observed} first-stage probabilities $p_0$ and $p_1$ vary with $(\alpha_0, \alpha_1)$ according to Lemma \ref{lem:p_pstar}.


\subsection{Simulation Results}

As explained in Section \ref{sec:problem} above, the just-identified, unconstrained GMM estimator based on Equation \ref{eq:MCs_endog} suffers from weak identification and boundary value problems.
Moreover, the estimator may not even exist in finite samples.
Even when the GMM estimator exists, its asymptotic variance matrix could be numerically singular, so that the standard GMM confidence interval is undefined.
Table \ref{tab:GMM_na_1000} reports the percentage of simulation draws for which the standard GMM confidence interval is undefined, while Table \ref{tab:GMM_cover_1000} reports the coverage probability and Table \ref{tab:GMM_width_1000} \emph{conditional} on the existence of the interval.

\begin{table}[htbp]
  \small
  \centering
  \input{./tab/GMM_CIs_na_1000.tex}
  \caption{Percentage of replications for which the standard GMM confidence interval based on Equation \ref{eq:MCs_endog} fails to exist, either because the point estimate is NaN or the asymptotic covariance matrix is numerically singular. Calculations are based on  2000 replications of the DGP from \ref{sec:DGP} with $n = 1000$.} 
  \label{tab:GMM_na_1000}
\end{table}

\begin{table}[htbp]
  \small
  \centering
  \input{./tab/GMM_CIs_cover_1000.tex}
  \caption{Coverage (\%) of the standard nominal 95\% GMM confidence interval for $\beta$ based on the Equation \ref{eq:MCs_endog}. Coverage is calculated only for those simulation draws for which the interval exists. (See Table \ref{tab:GMM_na_1000}.) Calculations are based on 2000 replications of the DGP from \ref{sec:DGP} with $n = 1000$.} 
  \label{tab:GMM_cover_1000}
\end{table}

\begin{table}[htbp]
  \small
  \centering
  \input{./tab/GMM_CIs_width_1000.tex}
  \caption{Median width of the standard nominal 95\% GMM confidence interval for $\beta$ based on the Equation \ref{eq:MCs_endog}. Coverage is calculated only for those simulation draws for which the interval exists. (See Table \ref{tab:GMM_na_1000}.) Calculations are based on 2000 replications of the DGP from \ref{sec:DGP} with $n = 1000$.} 
  \label{tab:GMM_width_1000}
\end{table}

We see from Table \ref{tab:GMM_na_1000} that when $\beta$ is small compared to the error variance, the GMM confidence interval fails to exist with high probability.
When $\beta = 0.5$, for example, the interval is undefined approximately 30\% of the time.
As $\beta$ increases, however, it becomes less likely that the GMM interval is undefined.
All else equal, larger amounts of mis-classification, i.e.\ higher values for $(\alpha_0, \alpha_1)$, increase the probability that the GMM interval fails to exist.
Turning our attention to the simulation draws for which it is well-defined, we see from Tables \ref{tab:GMM_cover_1000} and \ref{tab:GMM_width_1000} that the GMM confidence interval performs extremely poorly when $\beta$ is small.
Substantial size distortions persist until $\beta$ is 1.5 or larger.
All else equal, the size distortions are more severe the larger the amount of mis-classification error.


\todo[inline]{Change from here down!}
\begin{itemize}
  \item GMM does a bad job for small $\beta$ but a good job for large $\beta$.
    Note that we have changed our convention so we report coverage and width conditional on the interval existing!
  \item GMS test for $(\alpha_0, \alpha_1)$ uniformly controls size except for a small distortion at $\beta=3,\alpha_0=0.1$ that we can't explain.
  \item Now show the Bonferroni results:
    \begin{itemize}
      \item Uniformly controls size
      \item There is basically no conservatism in the zero measurement error case
      \item This comes from using the non-diff bounds (refer to the picture). Notice how these turn out to be very informative. They can only be informative from below, however, since $\alpha_0 = \alpha_1 = 0$ is always in the sharp identified set without our higher moment assumptions.
      \item When measurement error isn't zero, the method is conservative. 
      \item In the small $\beta$ cases, the conservatism is really a ``feature'' rather than a bug because there you are effectively not identified so we're really looking at an identified set.
      \item The conservatism is severe when $\beta$ is large and there is a lot of measurement error.
        The widths of the intervals are huge, although they do shrink with sample size.
        In contrast, GMM is working fine here.
      \item GMS doesn't seem to be able to ``detect'' the case where inference is standard. 
        Interesting question that doesn't seem to have been studied much about transitioning between partial and point identification (or weak and strong identification).
        We think the source of the conservatism is that we have an ellipse with a small variance in the beta direction and a large one in the alpha directions, so any kind of joint interval that we project will be very conservative for $\beta$. Maybe try to make a picture of this?
      \item Propose two-step procedure to address the conservatism when $\beta$ is large. 
        Explain the basic idea and show that it works perfectly and is essentially a free lunch. 
        There is one slight size distortion at $n = 1000,\beta = 1, \alpha_0 = \alpha_1 = 0.3$ but it disappears when $n = 2000$. Even small distortion at $\beta = 3, \alpha_0 = \alpha_1 = 0$ for both $n =1000, 2000$.
    \end{itemize}
\end{itemize}
