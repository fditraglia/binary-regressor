%!TEX root = ./main.tex
\section{Unobserved Heterogeneity}
\label{sec:het}
While allowing for arbitrary observed heterogeneity through the covariates $\mathbf{x}$, all of the results presented above assume an additively separable model -- Assumption \ref{assump:model} (i).
In this section we briefly discuss how our partial identification results can be interpreted in a local average treatment effects (LATE) setting.
For simplicity, we suppress explicit conditioning on the covariates $\mathbf{x}$ throughout. 

In lieu of Assumption \ref{assump:model} (i), consider a non-separable model of the form $y = h(T^*,z,\varepsilon)$.
Let $T^*(z)$ denote an individual's potential treatment and $Y(t^*,z)$ denote her potential outcome, where $t^*,z\in \left\{ 0,1 \right\}$.
Using this notation we can write $Y(t^*,z) = h(t^*,z,\varepsilon)$.
Let $J \in \left\{ a, c, d, n \right\}$ index the four LATE principal strata: $a = $ always-taker, $c = $ complier, $d = $ defier, and $n =$ never-taker.
If $J=a$, then $T^*(z) = 1$; if $J=c$, then $T^*(z) = z$; if $J=d$, then $T^*(z) = 1 - z$; and if $J=n$, then $T^*(z)=0$.
In a LATE model, Assumption \ref{assump:model} (iii) is replaced by the standard LATE assumptions:
\begin{assump}[Unconfounded Type]
    $\mathbb{P}(J=j|z=1) = \mathbb{P}(J=j|z=0)$ 
  for all  $j\in \left\{ a, c, d, n \right\}$.
\end{assump}
\begin{assump}[Mean Exclusion Restriction]
    For all $t^* \in \left\{ 0,1 \right\}$ and $j\in \left\{ a, c, d, n \right\}$,
    \[\mathbb{E}\left[Y(t^*,0)|T^*=t^*,z=1\right]=\mathbb{E}\left[Y(t^*,1)|T^*=t^*,z=1\right] = \mathbb{E}[Y(t^*)|J=j].\]
\end{assump}
\begin{assump}[Monotonicity]
    $\mathbb{P}\big(T^*(1) \geq T^*(0)\big) = 1$ 
\end{assump}

As is well known, Assumption \ref{assump:model} (iii) combined with the preceding three conditions implies that the (unobserved) instrumental variables estimand based on $T^*$ identifies the average treatment effect among compliers:
\[
  \frac{\mathbb{E}[y|z=1] - \mathbb{E}[y|z=0]}{p^*_1 - p^*_0} = \mathbb{E}[Y(1) - Y(0)|J=c].
\]
The numerator of the preceding expression is observed, but under mis-classification the denominator is not.
Notice, however, that Assumptions \ref{assump:misclassification} (i)--(ii) only concern the joint distribution of $T$ given $(T^*,z)$.
As such, they have the same meaning in a LATE model as in an additively separable model.
Imposing these conditions, Lemma \ref{lem:p_pstar} continues to hold in a LATE model.
It follows that $p_1 - p_0 = (1 - \alpha_0 - \alpha_1) (p_1^* - p_0^*)$ so that
\[
  \frac{\mathbb{E}[y|z=1] - \mathbb{E}[y|z=0]}{p_1 - p_0} = \frac{\mathbb{E}[Y(1) - Y(0)|J=c]}{1 - \alpha_0 - \alpha_1}.
\]
Moreover, $\alpha_0 \leq p_k \leq 1 - \alpha_1$ for all $k$.
Thus, the bound from Corollary \ref{cor:sharpBeta1} remains valid in a LATE model: $\mathbb{E}[Y(1) - Y(0)|J=c]$ must lie between the IV and reduced form estimands.
Unlike Assumptions \ref{assump:misclassification} (i)--(ii), Assumption \ref{assump:misclassification} (iii), non-differential measurement error, is explicitly stated in terms of the unobservable error term in an additively separable model.
Our derivation of the additional restrictions on $(\alpha_0, \alpha_1)$ implied by non-differential measurement error in the proof of Theorem \ref{thm:sharpII}, however, does not use Assumption \ref{assump:misclassification} (iii) directly.
Rather, it uses a condition that is \emph{equivalent} to it in an additively separable model, namely $\mathbb{E}[Y|T^*,T,z] = \mathbb{E}[Y|T^*,z]$.
Hence, as long as this equality holds, regardless of whether one is in an additively separable model or a LATE model, the bounds on $(\alpha_0, \alpha_1)$ from Theorem \ref{thm:sharpII} remain valid.
The appropriate translation of Assumption \ref{assump:misclassification} (iii) for a LATE model is as follows.
\begin{assump}[Non-differential Measurement Error]
  \[
    \mathbb{E}[Y(0)|T^*,T,z] = \mathbb{E}[Y(0)|T^*,z] \quad \mbox{and} \quad \mathbb{E}[Y(1)|T^*,T,z] = \mathbb{E}[Y(1)|T^*,z]
  \]
\end{assump}
Since $Y = (1 - T^*)Y(0) + T^* Y(1)$ in a LATE model, the preceding condition implies that $\mathbb{E}[Y|T^*,T,z] = \mathbb{E}[Y|T^*,z]$ as required.
herefore, if one wishes to re-interpret our $\beta$ as a local average treatment effect, the partial identification bounds from Theorem \ref{thm:sharpII} above remain valid.
In a LATE model, however, our proofs of sharpness no longer apply, as they do not consider the testable implications of the LATE assumptions themselves.
For partial identification results that consider these implications but do not impose non-differential measurement error, see \cite{Ura}.
For discussion of the testable implications of a LATE model, see \cite{kitagawa}.


%\todo[inline]{Although our results allow arbitrary observed heterogeneity, additive separability places restrictions on unobserved heterogeneity.
%  Although it is not the main focus of our paper, unlike Ura, briefly comment on how these results can be interpreted, say, in a LATE context. First, the bounds stuff all goes through (???) provided one is willing to make the LATE assumptions. Higher moment restrictions do impose restrictions. Can say what happens with the second moment assumption since we already derived this: it's a restriction on the variance of the potential outcome distributions, conditional on $\mathbf{x}$.}
%
%
%\subsubsection{Derivations from the Notes}
%
%\paragraph{Is there a LATE interpretation of our results?}
%Let $J \in \left\{ a, c, d, n \right\}$ index an individual's \emph{type}: always-taker, complier, defier, or never-taker.
%Let $\pi_a, \pi_c, \pi_d, \pi_n$ denote the population proportions of always-takers, compliers, defiers, and never-takers.
%The unconfounded type assumption is $P(J=j|z=1) = P(J=j|z=0)$.
%Combined with the law of total probability, this gives
%\begin{align*}
%  p^*_1 &= P(T^*=1|z=1) = \pi_a + \pi_c \\
%  1 - p^*_1 &= P(T^*=0|z=1) = \pi_d + \pi_n \\
%  p^*_0 &= P(T^*=1|z=0) = \pi_d + \pi_a \\
%  1-p^*_0 &= P(T^*=0|z=0) = \pi_n + \pi_c 
%\end{align*}
%Imposing no-defiers, $\pi_d = 0$, these expressions simplify to
%\begin{align*}
%  p^*_1 &=  \pi_a + \pi_c \\
%  1 - p^*_1 &=  \pi_n \\
%  p^*_0 &=  \pi_a \\
%  1-p^*_0 &=  \pi_n + \pi_c 
%\end{align*}
%Solving for $\pi_c$, we see that
%\begin{align*}
%  \pi_c &= p_1^* - p_0^*\\
%  \pi_a &= p_0^*\\
%  \pi_n &= 1 - p_1^*
%\end{align*}
%
%Now, let $Y(1)$ indicate the potential outcome when $T^*=1$ and $Y(0)$ indicate the potential outcome when $T^*=0$.
%The standard LATE assumptions (no defiers, mean exclusion, unconfounded type) imply
%\begin{align*}
%  \mathbb{E}\left( Y| T^* = 1, z = 1 \right) &= \left( \frac{p_0^*}{p_1^*} \right) \mathbb{E}\left[ Y(1)|J=a \right] + \left( \frac{p_1^* - p_0^*}{p_1^*} \right)\mathbb{E}\left[ Y(1)|J=c \right] \\
%  \mathbb{E}\left( Y| T^* = 0, z = 0 \right) &= \left( \frac{p_1^* - p_0^*}{1 - p_0^*} \right)\mathbb{E}\left[ Y(0)|J=c \right] + \left( \frac{1 - p_1^*}{1 - p_0^*} \right)\mathbb{E}\left[ Y(0)|J=n \right]\\
%  \mathbb{E}\left( Y| T^* = 1, z = 0 \right) &= \mathbb{E}\left[ Y(1)|J=a \right]\\
%  \mathbb{E}\left( Y| T^* = 0, z = 1 \right) &= \mathbb{E}\left[ Y(0)|J=n \right]
%\end{align*}
%
%
%
%\paragraph{LATE Version of Theorem 2 from original Draft}
%\begin{align*}
%  \Delta\overline{yT} &= \mathbb{E}\left( yT|z=1 \right) - \mathbb{E}\left( yT|z=0 \right) \\
%  &= (1 - \alpha_1) \left[ p_1^* \mathbb{E}\left( y|T^*=1, z=1 \right) - p_0^* \mathbb{E}\left(y|T^*=1, z=0\right) \right] \\
%  & \; \; \quad \quad + \alpha_0 \left[ (1 - p_1^*)\mathbb{E}\left( y|T^*=0, z=1\right) - (1 - p_0^*)\mathbb{E}\left(y|T^*,z=0 \right) \right]
%\end{align*}
%So we find that
%\begin{align*}
%  \Delta\overline{yT} &= (p_1^* - p_0^*)\left\{ (1 - \alpha_1) \mathbb{E}\left[ Y(1)|J=c \right] - \alpha_0\mathbb{E}\left[ Y(0)|J=c \right] \right\}\\
%  &= (1 - \alpha_1) \left\{ \frac{\mathbb{E}\left[ Y(1) - Y(0)|J=c \right]}{1 - \alpha_0 - \alpha_1} (p_1 - p_0) \right\} + (p_1  - p_0) \mathbb{E}\left[ Y(0)|J=c \right]
%\end{align*}
%Recall that the analogous expression in the homogeneous treatment effect case is
%\begin{align*}
%  \Delta\overline{yT} &= (1 - \alpha_1) \mathcal{W} (p_1 - p_0) + \mu_{10}^*\\
%  &= (1 - \alpha_1) \left(\frac{\beta}{1 - \alpha_0 - \alpha_1}\right) (p_1 - p_0) + (p_1 - \alpha_0)m_{11}^* - (p_0 - \alpha_0)m_{10}^*
%\end{align*}
%while the expression for the difference of variances is 
%\begin{align*}
%  \Delta\overline{y^2} &= \beta \mathcal{W}(p_1 - p_0) + 2\mathcal{W} \mu_{10}^*
%\end{align*}
%From above we see that the analogue of $\mu_{10}^*$ in the heterogeneous treatment effects setting is $(p_1 - p_0)E\left[ Y(0)|J=c \right]$ and since the LATE is $\mathbb{E}\left[ Y(1) - Y(0) |J=c\right]$, the analogue of $\mathcal{W}$ is
%\[
%  \frac{\mathbb{E}\left[ Y(1) - Y(0)|J=c \right]}{1 - \alpha_0 - \alpha_1}
%\]
%so \emph{if} we could establish that 
%\[
%  \Delta\overline{y^2} =  \left( \frac{p_1 - p_0}{1 - \alpha_0 - \alpha_1} \right)\mathbb{E}\left[ Y(1) - Y(0)|J=c \right]\cdot \mathbb{E}\left[ Y(1) + Y(0) |J=c \right]
%\]
%in the heterogeneous treatment effects case, the proof of Theorem 2 would go through immediately.
%Now, if we assume an exclusion restriction on the \emph{second} moment of $y$ an argument almost identical to the standard LATE derivation gives
%\[
%  \Delta\overline{y^2} = \frac{\mathbb{E}\left[ Y^2(1) - Y^2(0) |J=c \right]}{p_1^* - p_0^*} = \left( \frac{p_1 - p_0}{1 - \alpha_0 - \alpha_1} \right)\mathbb{E}\left[ Y^2(1) - Y^2(0) |J=c \right] 
%\]
%so we see that the necessary and sufficient condition for our proof to go through is 
%\[
%  \mathbb{E}\left[ Y^2(1) - Y^2(0)|J=c \right] = \mathbb{E}\left[ Y(1) - Y(0)|J=c \right]\cdot \mathbb{E}\left[ Y(1) + Y(0)|J=c \right]
%\]
%Rearranging, this in turn is equivalent to
%\[
%  \mbox{Var}\left[ Y(1)|J=c \right] = \mbox{Var}\left[ Y(0)|J=c \right]
%\]
%
