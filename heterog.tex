%!TEX root = ./main.tex
\section{Unobserved Heterogeneity}
\label{sec:het}
While allowing for arbitrary observed heterogeneity through the covariates $\mathbf{x}$, all of the results presented above assume an additively separable model -- Assumption \ref{assump:model} (i).
In this section we briefly discuss how our partial identification results can be interpreted in a local average treatment effects (LATE) setting.
For simplicity, we suppress explicit conditioning on the covariates $\mathbf{x}$ throughout. 

In lieu of Assumption \ref{assump:model} (i), consider a non-separable model of the form $y = h(T^*,z,\varepsilon)$.
Let $T^*(z)$ denote an individual's potential treatment and $Y(t^*,z)$ denote her potential outcome, where $t^*,z\in \left\{ 0,1 \right\}$.
Using this notation we can write $Y(t^*,z) = h(t^*,z,\varepsilon)$.
Let $J \in \left\{ a, c, d, n \right\}$ index the four LATE principal strata: $a = $ always-taker, $c = $ complier, $d = $ defier, and $n =$ never-taker.
If $J=a$, then $T^*(z) = 1$; if $J=c$, then $T^*(z) = z$; if $J=d$, then $T^*(z) = 1 - z$; and if $J=n$, then $T^*(z)=0$.
In a LATE model, Assumption \ref{assump:model} (iii) is replaced by the standard LATE assumptions:
\begin{assump}[Unconfounded Type]
  \label{assump:LATEtype}
    $\mathbb{P}(J=j|z=1) = \mathbb{P}(J=j|z=0)$ 
  for all  $j\in \left\{ a, c, d, n \right\}$.
\end{assump}
\begin{assump}[Mean Exclusion Restriction]
  \label{assump:LATEexclude}
    For all $t^* \in \left\{ 0,1 \right\}$ and $j\in \left\{ a, c, d, n \right\}$,
    \[\mathbb{E}\left[Y(t^*,0)|T^*=t^*,z=1\right]=\mathbb{E}\left[Y(t^*,1)|T^*=t^*,z=1\right] = \mathbb{E}[Y(t^*)|J=j].\]
\end{assump}
\begin{assump}[Monotonicity]
  \label{assump:LATEmono}
    $\mathbb{P}\big(T^*(1) \geq T^*(0)\big) = 1$ 
\end{assump}

As is well known, Assumption \ref{assump:model} (iii) combined with the preceding three conditions implies that the  instrumental variables estimand based on $T^*$ identifies the average treatment effect among compliers:
\[
  \frac{\mathbb{E}[y|z=1] - \mathbb{E}[y|z=0]}{p^*_1 - p^*_0} = \mathbb{E}[Y(1) - Y(0)|J=c].
\]
The numerator of the preceding expression is observed, but under mis-classification the denominator is not.
Notice, however, that Assumptions \ref{assump:misclassification} (i)--(ii) only concern the joint distribution of $T$ given $(T^*,z)$.
As such, they have the same meaning in a LATE model as in an additively separable model.
Imposing these conditions, Lemma \ref{lem:p_pstar} continues to hold in a LATE model.
It follows that $p_1 - p_0 = (1 - \alpha_0 - \alpha_1) (p_1^* - p_0^*)$ so that
\[
  \frac{\mathbb{E}[y|z=1] - \mathbb{E}[y|z=0]}{p_1 - p_0} = \frac{\mathbb{E}[Y(1) - Y(0)|J=c]}{1 - \alpha_0 - \alpha_1}.
\]
Moreover, $\alpha_0 \leq p_k \leq 1 - \alpha_1$ for all $k$.
Thus, the bound from Corollary \ref{cor:sharpBeta1} remains valid in a LATE model: $\mathbb{E}[Y(1) - Y(0)|J=c]$ must lie between the IV and reduced form estimands.

Unlike Assumptions \ref{assump:misclassification} (i)--(ii), Assumption \ref{assump:misclassification} (iii), non-differential measurement error, is explicitly stated in terms of the unobservable error term in an additively separable model.
Our derivation of the additional restrictions on $(\alpha_0, \alpha_1)$ implied by non-differential measurement error in the proof of Theorem \ref{thm:sharpII}, however, does not use Assumption \ref{assump:misclassification} (iii) directly.
Rather, it uses a condition that is \emph{equivalent} to it in an additively separable model, namely $\mathbb{E}[Y|T^*,T,z] = \mathbb{E}[Y|T^*,z]$.
Hence, as long as this equality holds, regardless of whether one is in an additively separable model or a LATE model, the bounds on $(\alpha_0, \alpha_1)$ from Theorem \ref{thm:sharpII} remain valid.
Since $Y = (1 - T^*)Y(0) + T^* Y(1)$, the appropriate modification of Assumption \ref{assump:misclassification} (iii) is as follows.
\begin{assump}[Non-differential Measurement Error]
  \label{assump:LATEnondiff}
  \[
    \mathbb{E}[Y(0)|T^*,T,z] = \mathbb{E}[Y(0)|T^*,z] \quad \mbox{and} \quad \mathbb{E}[Y(1)|T^*,T,z] = \mathbb{E}[Y(1)|T^*,z]
  \]
\end{assump}

To summarize, if one wishes to re-interpret our parameter $\beta$ as a local average treatment effect, the partial identification bounds from Theorems \ref{thm:sharpI} and \ref{thm:sharpII} above remain valid.
Assumption \ref{assump:model} (i) is replaced by $Y = h(T^*,z,\varepsilon)$, Assumption \ref{assump:model} (iii) is replaced by Assumptions \ref{assump:LATEtype}--\ref{assump:LATEmono}, and Assumption \ref{assump:misclassification} (iii) is replaced by Assumption \ref{assump:LATEnondiff}.
In a LATE model, however, our proofs of sharpness no longer apply, as they do not consider the testable implications of the LATE assumptions themselves.
For partial identification results that consider these implications but do not impose non-differential measurement error, see \cite{Ura}.
For discussion of the testable implications of a LATE model, see \cite{kitagawa}.

