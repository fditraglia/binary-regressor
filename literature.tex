%!TEX root = ./main.tex
\section{Notation and Related Literature}
\todo[inline]{Give the general model, the full notation, and the shorthand notation. Also give the ``m'' notation since this will make it easier to talk about the papers.}

\todo[inline]{Why is this model interesting? What is known about it?}
Many treatments of interest in applied work are binary.
To take a particularly prominent example, consider treatment status in a randomized controlled trial.
Even if the randomization is pristine, which yields a valid binary instrument (the offer of treatment), subjects may select into treatment based on unobservables, and, given the given the many real-world complications that arise in the field, measurement error may be an important concern.
As is well known, instrumental variables (IV) based on a single valid instrument suffices to recover the treatment effect in a linear model with a single endogenous regressor subject to classical measurement.
As is less well known, classical measurement error is in fact impossible when the regressor of interest is binary: because a true 1 can only be mis-measured as a 0 and a true 0 can only be mis-measured as a 1, the measurement error must be \emph{negatively} correlated with the true treatment status \citep{Aigner,Bollinger}. 

Measurement error in binary regressor is usually called \emph{mis-classification}.
The simplest form of mis-classification is so-called \emph{non-differential} measurement error.
In this case, conditional on true treatment status, and possibly a set of exogenous covariates, the measurement error is assumed to be un-correlated with the other variables of the system.
Even under this comparatively mild departure from classical measurement error, \cite{Bollinger} has shown that the IV estimator does not recover the true treatment effect: while the IV estimator removes the effect of regressor endogeneity it is inconsistent and the asymptotic bias depends on the extent of measurement error.
When the regressor of interest is in fact \emph{exogenous}, however, and a valid instrument is available, it is possible to recover the treatment effect using a GMM approach.
\cite{BBS} and \cite{KRS} more-or-less simultaneously pointed this out in a setting in which \emph{two} alternative measures of treatment are available, both subject to non-differential measurement error.
In essence, one measure serves as an instrument for the other although the estimator is quite different from IV.\footnote{Ignoring covariates, the observable moments in this case are the joint probability distribution of the two binary treatment measures and the conditional means of the outcome variable given the two measure. Although the system is highly non-linear, it can be manipulated to yield an explicit solution for the treatment effect provided that the true treatment is exogenous.}






Unfortunately, IV is inconsistent under non-differential measurement error: removes only the effect of endogeneity, not measurement error.
Papers that explain how to construct a method of moments estimator, not IV, that uses an instrument, or second measure, to eliminate non-differential measurement error when the treatment of interest is \emph{exogenous}: \cite{KRS}, \cite{BBS}, \cite{FL}.
Later generalizations of this idea by \cite{Lewbel} and \cite{Mahajan}.

Only two papers discuss case in which the treatment is endogenous as well as mis-classified and they reach apparently contradictory conclusions.
(Should also mention the \cite{Hausman} and Tanguay Brachet stuff, although identification here is really ``at infinity'' and depends crucially on the parametric specification.)
While most of their paper is devoted to case of exogenous treatment, \cite{FL} spend a few paragraphs discussing extension to endogenous treatment.
Although do not provide a formal proof, argue the model won't be identified except under very strong parametric restrictions since relaxing exogeneity introduces two new parameters.
\cite{FL} consider traditional linear IV model making no distinction between continuous and discrete instrument.
In contrast \cite{Mahajan}, apparently unaware of \cite{FL},  concludes that the treatment effect is identified under endogeneity and mis-classification.
Clearly there is some confusion in the literature about these kinds of models, main goal of this paper is to clarify what can and cannot be learned about a causal effect in the presence of mis-classification and endogeneity. 
Present a general analysis of non-parametric identification in this setting.
Key ingredient: put existing papers into a common framework, including \cite{Lewbel} who works with an ``instrument'' that actually has a direct effect on the outcome.
Explain the model we will work with here and how we hold covariates fixed as in the proofs of other papers, how this allows us to simplify notation.
Introduce the ``m'' notation.




Summary of our findings goes here. 
First, the analysis in both \cite{FL} and \cite{Mahajan} is flawed.
\cite{FL} get the exogeneity assumption wrong while \cite{Mahajan} assumes a contradiction: no first stage.
We Consider ways to get extra moment conditions to try to achieve identification: homoskedasticity restriction and additional values of instrument, a la \cite{Lewbel}.
The homoskedasticity condition yields a simple and informative partial identification result regardless of the number of values the instrument takes on.
Presumably we will prove that no matter how many values the instrument takes on, we can't get identification, with or without the homoskedasticity condition.
Possibly consider some additional restrictions on the $m^*_{jk}$ that would yield identification: some kind of symmetry condition on selection or something.
Probably these assumptions aren't very plausible in practice.
Summary of paper.
Example from development experiment?
Proofs in appendix.
\todo[inline]{Should probably start off, possible in previous section, by writing out a general encompassing framework that will allow us to talk about all the papers in this section. Present our model before this section. Should also mention the assumption $1-\alpha_0-\alpha_1>0$.}

Many examples want to estimate effect of binary treatment.
Often treatment is mis-measured and possibly endogenous.
Measurement error in binary regressor cannot be classical.
This has been know for a while, see \cite{Aigner} and \cite{Bollinger}.
Intuition: can only mis-code true zero and one and true one as zero.
Describe non-differential measurement error idea.
Under this kind of measurement error, IV estimator is inconsistent for the causal effect: can remove the effect of endogeneity but not of measurement error.
See for example \cite{KRS,BBS,FL}.


Now talk about \cite{KRS} and \cite{BBS}.
Two measures of exogenous binary treatment with non-differential measurement error allow one to identify treatment effect.
Method of moments estimator \emph{not} IV.
Relies on discreteness of the problem: construct ``cells'' for $E[y|z,T]$.
Talk about how the two papers differ in their contribution.
\cite{BBS} consider not only the binary case but a continuous version that isn't identified.
\todo[inline]{Need to figure out how \cite{Card} relates to these as well.
It looks like he does not in fact use two measures to estimate the effect of union status on wages. Instead he uses a two-period panel dataset and examines external information comparing employer and employee reporting of union status. This leads him to propose the assumption that the ``up'' and ``down'' mis-classification probabilities are equal, since it fits this external dataset well. This is the ``quasi-classical'' measurement error case that we talked about previously. There is only one measurement error parameter and presumably the panel dataset allows him to identify it.}

\cite{FL} point out that an instrument can be used in place of a second measure of $T^*$ provided that $T^*$ is still exogenous.
Essentially the same estimator as in \cite{BBS} and \cite{KRS} but more general since the instrument need not be binary: can in fact be continuous.
But they make a mistake. 
They assume $E[zu]=0$, $E[T^*u]=0$ and non-differential measurement error and claim that this is sufficient to consistently estimate $\beta$.
However, this is incorrect: we need the additional assumption that $E[zT^*u]=0$ which is stronger.
(They seem to think that this term only appears when you have an endogenous $T^*$.)
While \cite{FL} are aware that there are some differences between two measures of $T^*$, as in \cite{BBS}, and an arbitrary instrument $z$, they seem to have missed one subtle point.
The assumptions in \cite{BBS} in fact imply that $E[u|T^*,z]=0$.\footnote{This follows from Assumptions A1 and A2 combined with Equation 3.}
From this it follows that $E[zT^*u]=E[zu]=E[T^*u]=0$. 
However, if one takes the non-differential measurement assumption literally it is in fact sufficient in the case of two measures to assume only that $E[zu]=E[T^*u]=0$:
\begin{align}
  E[zT^*u] &= E[(T^*+w)T^*u] = E[(T^*)^2u] + E[wuT^*]  \\
  &= E\left[ E\left( u|T^* \right)(T^*)^2 \right] + E\left[E\left( wu|T^* \right)T^*\right]\\
  &= 0 + E\left[ E(w|T^*)E(u|T^*)T^* \right] = 0
\end{align}
using the fact that $E[u|T^*]=0$ and $w$ is independent of $u$ conditional on $T^*$.
This argument does \emph{not} necessarily apply to an arbitrary instrument $z$: $E[zu]=E[T^*u]=0$ does not imply that $E[zT^*u]=0$.
\todo[inline]{Put in our simple binary example.}
While it might seem strange to assume in practice that $E[zu]=E[T^*u]=0$ are exogenous but not that $E[zT^*u]=0$ the point is merely that this is an additional assumption beyond the usual assumptions of lack of correlation. 


\cite{FL} also briefly discuss case in which $T^*$ is endogenous, basically conclude that all you can get in this case is bounds for the treatment effect.
\todo[inline]{Presumably we're going to show that this isn't the case!}

\cite{Mahajan} considers the case of a binary regressor subject to non-differential measurement error when one has available a binary instrument (he calls it an ILV).
Doesn't seem to be aware of \cite{FL}, similar to \cite{BBS} and \cite{KRS} although he allows for non-parametric effects of covariates and allows the mis-classification error rates to depend on covariates.
(Although since covariates are held fixed in the proofs, this isn't a big deal.)
The crucial assumption for the instrument-like variable is that it is unrelated to the mis-classification probabilities.
Uses the assumption $E[u|T^*,z]$ to get identification using same basic estimator as \cite{BBS}.
Also says that he can get identification when $T^*$ is endogenous, but this is wrong.
He correctly shows that it would be sufficient to learn the mis-classification error rates (as we know, the IV estimator converges to $\beta/(1-\alpha_0-\alpha_1)$ even when $T^*$ is endogenous).
However, he then states that his earlier theorem has proven that these rates are identified. 
That theorem, however, relies crucially on the assumption that $T^*$ is exogenous!

Another closely related paper is \cite{Lewbel}.
Whereas Mahajan makes sufficient assumptions to identify $\beta$ with a two-valued $z$, provided that $T^*$ is exogenous, Lewbel works with a three-valued $z$.
While Lewbel also assumes that $E[T^*u]=0$, his ``instrument'' is really more like a covariate.
He assumes that $z$ is unrelated to the mis-classification probabilities but allows it to have a direct effect on $y$, as long as there is no interaction between $T^*$ and $z$.
Since this involves imposing fewer restrictions on the $m_{ij}$, Lewbel requires that $z$ take on more values.
There is also some kind of determinant condition that we don't fully understand yet, but will figure out soon!




















